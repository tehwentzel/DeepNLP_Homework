{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing.pool import Pool\n",
    "import re\n",
    "positive_file = 'data/rt-polarity.pos'\n",
    "negative_file = 'data/rt-polarity.neg'\n",
    "data_root = 'data/stanfordSentimentTreebank/'\n",
    "glove_pattern = 'data/glove.6B.<size>d.txt'\n",
    "glove_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove(size = 50):\n",
    "    file = re.sub('<size>', str(size), glove_pattern)\n",
    "    glove = pd.read_csv(file, sep = \" \", header = None, index_col = 0, quoting = 3)\n",
    "    glove = {key: val.values for key, val in glove.T.items()}\n",
    "    return glove\n",
    "\n",
    "def preprocess_sentence(line):\n",
    "    line = re.sub(r'[^\\x00-\\x7F]+', '', line.strip())\n",
    "    return line.strip().lower()\n",
    "\n",
    "def preprocess_for_labels(line):\n",
    "    line = preprocess_sentence(line)\n",
    "    line = re.sub('\\W+', '', line.strip())\n",
    "    return line\n",
    "    \n",
    "def get_labelset(file):\n",
    "    with open(file, \"rt\", encoding=\"utf-8\") as f:\n",
    "        sentences = set([preprocess_for_labels(line) for line in f.readlines()])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_labelset = get_labelset(positive_file)\n",
    "negative_labelset = get_labelset(negative_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_dict = {}\n",
    "data_split_map = {'1': 'train', '2': 'test', '3':'val'}\n",
    "with open(data_root + 'datasetSplit.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        [index, set_code] = line.strip().split(',')\n",
    "        try:\n",
    "            index = int(index)\n",
    "        except:\n",
    "            continue\n",
    "        if set_code not in data_split_map:\n",
    "            print(index, set_code)\n",
    "        data_split_dict[index] = data_split_map.get(set_code, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2775  skipped\n",
      "9077  kept\n"
     ]
    }
   ],
   "source": [
    "def check_sentiment(sentence):\n",
    "    s = preprocess_for_labels(sentence)\n",
    "    for y, labelset in enumerate([negative_labelset, positive_labelset]):\n",
    "        for entry in labelset:\n",
    "            if s in labelset:\n",
    "                return y\n",
    "    return -1\n",
    "\n",
    "sentences = {}\n",
    "word2ind = {}\n",
    "ttws = tf.keras.preprocessing.text.text_to_word_sequence\n",
    "n_skipped = 0\n",
    "idx = 0\n",
    "with open(data_root + 'datasetSentences.txt') as data:\n",
    "    lines = data.readlines()\n",
    "    for line in lines:\n",
    "        index = re.search('^\\d+', line)\n",
    "        if index is None:\n",
    "            continue\n",
    "        index = int(index.group())\n",
    "        if index not in data_split_dict:\n",
    "            print(index, line)\n",
    "        entry = {'split_set': data_split_dict.get(index, 'val')}\n",
    "        line = preprocess_sentence(line)\n",
    "        line = re.sub(r'^\\d+\\s+', '', line)\n",
    "        sentiment = check_sentiment(line)\n",
    "        if sentiment >= 0:\n",
    "            entry['y'] = sentiment\n",
    "        else:\n",
    "            n_skipped += 1\n",
    "            continue\n",
    "        sentences[line] = entry\n",
    "        tokens = ttws(line)\n",
    "        for token in tokens:\n",
    "            if token not in word2ind:\n",
    "                word2ind[token] = idx\n",
    "                idx = idx + 1\n",
    "            \n",
    "print(n_skipped, ' skipped')\n",
    "print(len(sentences), ' kept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = {title: {'x':[], 'y':[]} for title in ['train', 'test', 'val']}\n",
    "for line, entry in sentences.items():\n",
    "    which = entry['split_set']\n",
    "    tokenized = [int(word2ind[token]) for token in ttws(line)]\n",
    "    (data_splits[which]['x']).append(tokenized)\n",
    "    (data_splits[which]['y']).append(int(entry['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(label, sequence_len):\n",
    "    vals = data_splits[label]\n",
    "    x = [np.array(vx) for vx in vals['x']]\n",
    "    x = tf.keras.preprocessing.sequence.pad_sequences(x, \n",
    "                                                      maxlen = sequence_len)\n",
    "    y = np.array(vals['y'])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(glove_size):\n",
    "    glove = get_glove(glove_size)\n",
    "    glove_words = set(glove.keys())\n",
    "    default_vector = np.mean(list(glove.values()), axis = 0)\n",
    "    embedding_matrix = np.empty((len(word2ind), default_vector.shape[0]))\n",
    "    excluded = []\n",
    "    for word, position in word2ind.items():\n",
    "        if word not in glove:\n",
    "            excluded.append(word)\n",
    "        embedding_matrix[position,:] = glove.get(word, default_vector)\n",
    "    print(len(excluded), ' words from dataset not in glove')\n",
    "    return embedding_matrix\n",
    "\n",
    "def gen_model(layer_type = tf.keras.layers.SimpleRNN, \n",
    "              trainable = False, n_layers = 1, \n",
    "              n_hidden_states = 8, lr = .01,\n",
    "              embedding_matrix = None, glove_size = 300):\n",
    "    if embedding_matrix is None:\n",
    "        embedding_matrix = get_embedding_matrix(glove_size)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(embedding_matrix.shape[0], \n",
    "                               embedding_matrix.shape[1], \n",
    "                               embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                               trainable = trainable)\n",
    "             )\n",
    "    for n in range(n_layers - 1):\n",
    "        model.add(layer_type(n_hidden_states, return_sequences = True))\n",
    "    model.add(layer_type(n_hidden_states))\n",
    "    model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics = ['BinaryAccuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(epochs = 100, batch_size = 500, sequence_len = 50, model_args = {}):\n",
    "    (xtrain, ytrain)= get_dataset('train', sequence_len)\n",
    "    (xtest, ytest) = get_dataset('test', sequence_len)\n",
    "    (xval, yval) = get_dataset('val', sequence_len)\n",
    "    model = gen_model(**model_args)\n",
    "    train_history = model.fit(xtrain, ytrain, \n",
    "                              validation_data = (xval, yval),\n",
    "                              batch_size = batch_size,\n",
    "                              epochs = epochs)\n",
    "    return train_history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398  words from dataset not in glove\n",
      "Train on 6530 samples, validate on 845 samples\n",
      "Epoch 1/100\n",
      "6530/6530 [==============================] - 1s 179us/sample - loss: 0.7023 - binary_accuracy: 0.5613 - val_loss: 0.6529 - val_binary_accuracy: 0.6178\n",
      "Epoch 2/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.6304 - binary_accuracy: 0.6346 - val_loss: 0.6469 - val_binary_accuracy: 0.6260\n",
      "Epoch 3/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.6121 - binary_accuracy: 0.6590 - val_loss: 0.6194 - val_binary_accuracy: 0.6686\n",
      "Epoch 4/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.5703 - binary_accuracy: 0.7034 - val_loss: 0.6277 - val_binary_accuracy: 0.6651\n",
      "Epoch 5/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.5350 - binary_accuracy: 0.7386 - val_loss: 0.5186 - val_binary_accuracy: 0.7527\n",
      "Epoch 6/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.5304 - binary_accuracy: 0.7443 - val_loss: 0.5472 - val_binary_accuracy: 0.7361\n",
      "Epoch 7/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.5381 - binary_accuracy: 0.7351 - val_loss: 0.5909 - val_binary_accuracy: 0.7018\n",
      "Epoch 8/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.5119 - binary_accuracy: 0.7530 - val_loss: 0.6018 - val_binary_accuracy: 0.7089\n",
      "Epoch 9/100\n",
      "6530/6530 [==============================] - 0s 46us/sample - loss: 0.5285 - binary_accuracy: 0.7357 - val_loss: 0.5438 - val_binary_accuracy: 0.7420\n",
      "Epoch 10/100\n",
      "6530/6530 [==============================] - 0s 45us/sample - loss: 0.4967 - binary_accuracy: 0.7662 - val_loss: 0.5203 - val_binary_accuracy: 0.7467\n",
      "Epoch 11/100\n",
      "6530/6530 [==============================] - 0s 45us/sample - loss: 0.4776 - binary_accuracy: 0.7799 - val_loss: 0.5132 - val_binary_accuracy: 0.7609\n",
      "Epoch 12/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4604 - binary_accuracy: 0.7928 - val_loss: 0.5068 - val_binary_accuracy: 0.7763\n",
      "Epoch 13/100\n",
      "6530/6530 [==============================] - 0s 45us/sample - loss: 0.4603 - binary_accuracy: 0.7966 - val_loss: 0.5151 - val_binary_accuracy: 0.7609\n",
      "Epoch 14/100\n",
      "6530/6530 [==============================] - 0s 47us/sample - loss: 0.5332 - binary_accuracy: 0.7389 - val_loss: 0.5610 - val_binary_accuracy: 0.7195\n",
      "Epoch 15/100\n",
      "6530/6530 [==============================] - 0s 45us/sample - loss: 0.5035 - binary_accuracy: 0.7603 - val_loss: 0.5315 - val_binary_accuracy: 0.7538\n",
      "Epoch 16/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4814 - binary_accuracy: 0.7781 - val_loss: 0.5472 - val_binary_accuracy: 0.7444\n",
      "Epoch 17/100\n",
      "6530/6530 [==============================] - 0s 45us/sample - loss: 0.4747 - binary_accuracy: 0.7796 - val_loss: 0.6039 - val_binary_accuracy: 0.7302\n",
      "Epoch 18/100\n",
      "6530/6530 [==============================] - 0s 46us/sample - loss: 0.5395 - binary_accuracy: 0.7355 - val_loss: 0.5985 - val_binary_accuracy: 0.7053\n",
      "Epoch 19/100\n",
      "6530/6530 [==============================] - 0s 45us/sample - loss: 0.4997 - binary_accuracy: 0.7614 - val_loss: 0.5280 - val_binary_accuracy: 0.7550\n",
      "Epoch 20/100\n",
      "6530/6530 [==============================] - 0s 45us/sample - loss: 0.4704 - binary_accuracy: 0.7896 - val_loss: 0.5281 - val_binary_accuracy: 0.7574\n",
      "Epoch 21/100\n",
      "6530/6530 [==============================] - 0s 45us/sample - loss: 0.4635 - binary_accuracy: 0.7850 - val_loss: 0.5269 - val_binary_accuracy: 0.7527\n",
      "Epoch 22/100\n",
      "6530/6530 [==============================] - 0s 45us/sample - loss: 0.4641 - binary_accuracy: 0.7888 - val_loss: 0.5368 - val_binary_accuracy: 0.7420\n",
      "Epoch 23/100\n",
      "6530/6530 [==============================] - 0s 46us/sample - loss: 0.4616 - binary_accuracy: 0.7850 - val_loss: 0.5904 - val_binary_accuracy: 0.7444\n",
      "Epoch 24/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.5578 - binary_accuracy: 0.7227 - val_loss: 0.5980 - val_binary_accuracy: 0.6899\n",
      "Epoch 25/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.5330 - binary_accuracy: 0.7303 - val_loss: 0.5440 - val_binary_accuracy: 0.7302\n",
      "Epoch 26/100\n",
      "6530/6530 [==============================] - 0s 46us/sample - loss: 0.4854 - binary_accuracy: 0.7712 - val_loss: 0.5260 - val_binary_accuracy: 0.7562\n",
      "Epoch 27/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4961 - binary_accuracy: 0.7701 - val_loss: 0.5615 - val_binary_accuracy: 0.7290\n",
      "Epoch 28/100\n",
      "6530/6530 [==============================] - 0s 46us/sample - loss: 0.4826 - binary_accuracy: 0.7767 - val_loss: 0.5669 - val_binary_accuracy: 0.7302\n",
      "Epoch 29/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4667 - binary_accuracy: 0.7853 - val_loss: 0.5575 - val_binary_accuracy: 0.7503\n",
      "Epoch 30/100\n",
      "6530/6530 [==============================] - 0s 46us/sample - loss: 0.4802 - binary_accuracy: 0.7784 - val_loss: 0.5561 - val_binary_accuracy: 0.7266\n",
      "Epoch 31/100\n",
      "6530/6530 [==============================] - 0s 45us/sample - loss: 0.4617 - binary_accuracy: 0.7847 - val_loss: 0.5397 - val_binary_accuracy: 0.7680\n",
      "Epoch 32/100\n",
      "6530/6530 [==============================] - 0s 47us/sample - loss: 0.4585 - binary_accuracy: 0.7879 - val_loss: 0.5805 - val_binary_accuracy: 0.7183\n",
      "Epoch 33/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4700 - binary_accuracy: 0.7796 - val_loss: 0.5345 - val_binary_accuracy: 0.7491\n",
      "Epoch 34/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4450 - binary_accuracy: 0.8017 - val_loss: 0.5346 - val_binary_accuracy: 0.7621\n",
      "Epoch 35/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4314 - binary_accuracy: 0.8038 - val_loss: 0.5768 - val_binary_accuracy: 0.7444\n",
      "Epoch 36/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4473 - binary_accuracy: 0.7971 - val_loss: 0.5440 - val_binary_accuracy: 0.7515\n",
      "Epoch 37/100\n",
      "6530/6530 [==============================] - 0s 41us/sample - loss: 0.4364 - binary_accuracy: 0.8032 - val_loss: 0.5582 - val_binary_accuracy: 0.7527\n",
      "Epoch 38/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4400 - binary_accuracy: 0.8040 - val_loss: 0.5575 - val_binary_accuracy: 0.7396\n",
      "Epoch 39/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4326 - binary_accuracy: 0.8021 - val_loss: 0.5381 - val_binary_accuracy: 0.7538\n",
      "Epoch 40/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4263 - binary_accuracy: 0.8115 - val_loss: 0.5510 - val_binary_accuracy: 0.7598\n",
      "Epoch 41/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4128 - binary_accuracy: 0.8184 - val_loss: 0.5694 - val_binary_accuracy: 0.7396\n",
      "Epoch 42/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4218 - binary_accuracy: 0.8124 - val_loss: 0.5591 - val_binary_accuracy: 0.7361\n",
      "Epoch 43/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4179 - binary_accuracy: 0.8145 - val_loss: 0.5784 - val_binary_accuracy: 0.7361\n",
      "Epoch 44/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4102 - binary_accuracy: 0.8201 - val_loss: 0.5733 - val_binary_accuracy: 0.7574\n",
      "Epoch 45/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4118 - binary_accuracy: 0.8178 - val_loss: 0.5643 - val_binary_accuracy: 0.7278\n",
      "Epoch 46/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.3986 - binary_accuracy: 0.8271 - val_loss: 0.5717 - val_binary_accuracy: 0.7503\n",
      "Epoch 47/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4357 - binary_accuracy: 0.8005 - val_loss: 0.5879 - val_binary_accuracy: 0.7101\n",
      "Epoch 48/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4385 - binary_accuracy: 0.8032 - val_loss: 0.6214 - val_binary_accuracy: 0.6923\n",
      "Epoch 49/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4645 - binary_accuracy: 0.7822 - val_loss: 0.5912 - val_binary_accuracy: 0.7030\n",
      "Epoch 50/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4309 - binary_accuracy: 0.8095 - val_loss: 0.5670 - val_binary_accuracy: 0.7314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4105 - binary_accuracy: 0.8165 - val_loss: 0.6002 - val_binary_accuracy: 0.7385\n",
      "Epoch 52/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.5389 - binary_accuracy: 0.7521 - val_loss: 0.6064 - val_binary_accuracy: 0.6888\n",
      "Epoch 53/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4774 - binary_accuracy: 0.7758 - val_loss: 0.5895 - val_binary_accuracy: 0.7148\n",
      "Epoch 54/100\n",
      "6530/6530 [==============================] - 0s 41us/sample - loss: 0.4515 - binary_accuracy: 0.7959 - val_loss: 0.5682 - val_binary_accuracy: 0.7396\n",
      "Epoch 55/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4178 - binary_accuracy: 0.8168 - val_loss: 0.5649 - val_binary_accuracy: 0.7408\n",
      "Epoch 56/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4214 - binary_accuracy: 0.8107 - val_loss: 0.5551 - val_binary_accuracy: 0.7456\n",
      "Epoch 57/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4030 - binary_accuracy: 0.8207 - val_loss: 0.5616 - val_binary_accuracy: 0.7254\n",
      "Epoch 58/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.3984 - binary_accuracy: 0.8256 - val_loss: 0.5704 - val_binary_accuracy: 0.7361\n",
      "Epoch 59/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.3945 - binary_accuracy: 0.8276 - val_loss: 0.5731 - val_binary_accuracy: 0.7254\n",
      "Epoch 60/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.3956 - binary_accuracy: 0.8273 - val_loss: 0.5760 - val_binary_accuracy: 0.7314\n",
      "Epoch 61/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.3950 - binary_accuracy: 0.8309 - val_loss: 0.6123 - val_binary_accuracy: 0.7278\n",
      "Epoch 62/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.3985 - binary_accuracy: 0.8276 - val_loss: 0.5856 - val_binary_accuracy: 0.7302\n",
      "Epoch 63/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4050 - binary_accuracy: 0.8207 - val_loss: 0.6119 - val_binary_accuracy: 0.7361\n",
      "Epoch 64/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.3971 - binary_accuracy: 0.8283 - val_loss: 0.6012 - val_binary_accuracy: 0.7243\n",
      "Epoch 65/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.3932 - binary_accuracy: 0.8292 - val_loss: 0.6711 - val_binary_accuracy: 0.6805\n",
      "Epoch 66/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4954 - binary_accuracy: 0.7594 - val_loss: 0.6160 - val_binary_accuracy: 0.7030\n",
      "Epoch 67/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4155 - binary_accuracy: 0.8145 - val_loss: 0.6263 - val_binary_accuracy: 0.7314\n",
      "Epoch 68/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4017 - binary_accuracy: 0.8257 - val_loss: 0.5834 - val_binary_accuracy: 0.7337\n",
      "Epoch 69/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.3881 - binary_accuracy: 0.8311 - val_loss: 0.5903 - val_binary_accuracy: 0.7385\n",
      "Epoch 70/100\n",
      "6530/6530 [==============================] - 0s 41us/sample - loss: 0.3944 - binary_accuracy: 0.8328 - val_loss: 0.7186 - val_binary_accuracy: 0.6911\n",
      "Epoch 71/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4747 - binary_accuracy: 0.7744 - val_loss: 0.6369 - val_binary_accuracy: 0.6734\n",
      "Epoch 72/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4645 - binary_accuracy: 0.7874 - val_loss: 0.6289 - val_binary_accuracy: 0.7041\n",
      "Epoch 73/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4749 - binary_accuracy: 0.7874 - val_loss: 0.5890 - val_binary_accuracy: 0.7053\n",
      "Epoch 74/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4145 - binary_accuracy: 0.8204 - val_loss: 0.5690 - val_binary_accuracy: 0.7231\n",
      "Epoch 75/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4276 - binary_accuracy: 0.8104 - val_loss: 0.6077 - val_binary_accuracy: 0.6817\n",
      "Epoch 76/100\n",
      "6530/6530 [==============================] - 0s 46us/sample - loss: 0.4821 - binary_accuracy: 0.7711 - val_loss: 0.6345 - val_binary_accuracy: 0.7172\n",
      "Epoch 77/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4990 - binary_accuracy: 0.7720 - val_loss: 0.6007 - val_binary_accuracy: 0.7089\n",
      "Epoch 78/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4789 - binary_accuracy: 0.7824 - val_loss: 0.5731 - val_binary_accuracy: 0.7053\n",
      "Epoch 79/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4290 - binary_accuracy: 0.8113 - val_loss: 0.6312 - val_binary_accuracy: 0.6994\n",
      "Epoch 80/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.6645 - binary_accuracy: 0.7096 - val_loss: 0.5829 - val_binary_accuracy: 0.7231\n",
      "Epoch 81/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.5591 - binary_accuracy: 0.7194 - val_loss: 0.5861 - val_binary_accuracy: 0.6947\n",
      "Epoch 82/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.5270 - binary_accuracy: 0.7492 - val_loss: 0.5638 - val_binary_accuracy: 0.7124\n",
      "Epoch 83/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.5357 - binary_accuracy: 0.7501 - val_loss: 0.5796 - val_binary_accuracy: 0.7160\n",
      "Epoch 84/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.5036 - binary_accuracy: 0.7686 - val_loss: 0.5555 - val_binary_accuracy: 0.7266\n",
      "Epoch 85/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.5008 - binary_accuracy: 0.7675 - val_loss: 0.5639 - val_binary_accuracy: 0.7314\n",
      "Epoch 86/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4902 - binary_accuracy: 0.7708 - val_loss: 0.5607 - val_binary_accuracy: 0.7337\n",
      "Epoch 87/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4776 - binary_accuracy: 0.7757 - val_loss: 0.5779 - val_binary_accuracy: 0.7254\n",
      "Epoch 88/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4668 - binary_accuracy: 0.7844 - val_loss: 0.5780 - val_binary_accuracy: 0.7278\n",
      "Epoch 89/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4698 - binary_accuracy: 0.7779 - val_loss: 0.5803 - val_binary_accuracy: 0.7243\n",
      "Epoch 90/100\n",
      "6530/6530 [==============================] - 0s 41us/sample - loss: 0.4901 - binary_accuracy: 0.7761 - val_loss: 0.5593 - val_binary_accuracy: 0.7243\n",
      "Epoch 91/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4780 - binary_accuracy: 0.7824 - val_loss: 0.5736 - val_binary_accuracy: 0.7314\n",
      "Epoch 92/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4969 - binary_accuracy: 0.7680 - val_loss: 0.6150 - val_binary_accuracy: 0.7030\n",
      "Epoch 93/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.5327 - binary_accuracy: 0.7470 - val_loss: 0.5943 - val_binary_accuracy: 0.6899\n",
      "Epoch 94/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.5056 - binary_accuracy: 0.7557 - val_loss: 0.5581 - val_binary_accuracy: 0.7219\n",
      "Epoch 95/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4770 - binary_accuracy: 0.7825 - val_loss: 0.5478 - val_binary_accuracy: 0.7219\n",
      "Epoch 96/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.5121 - binary_accuracy: 0.7577 - val_loss: 0.5561 - val_binary_accuracy: 0.7325\n",
      "Epoch 97/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4885 - binary_accuracy: 0.7671 - val_loss: 0.5435 - val_binary_accuracy: 0.7396\n",
      "Epoch 98/100\n",
      "6530/6530 [==============================] - 0s 43us/sample - loss: 0.4515 - binary_accuracy: 0.7940 - val_loss: 0.5419 - val_binary_accuracy: 0.7373\n",
      "Epoch 99/100\n",
      "6530/6530 [==============================] - 0s 44us/sample - loss: 0.4350 - binary_accuracy: 0.8034 - val_loss: 0.5534 - val_binary_accuracy: 0.7408\n",
      "Epoch 100/100\n",
      "6530/6530 [==============================] - 0s 42us/sample - loss: 0.4246 - binary_accuracy: 0.8087 - val_loss: 0.5543 - val_binary_accuracy: 0.7266\n"
     ]
    }
   ],
   "source": [
    "vanilla_rnn_hist = run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398  words from dataset not in glove\n",
      "Train on 6530 samples, validate on 845 samples\n",
      "Epoch 1/100\n",
      "6530/6530 [==============================] - 2s 308us/sample - loss: 0.6251 - binary_accuracy: 0.6510 - val_loss: 0.4907 - val_binary_accuracy: 0.7799\n",
      "Epoch 2/100\n",
      "6530/6530 [==============================] - 1s 127us/sample - loss: 0.4956 - binary_accuracy: 0.7632 - val_loss: 0.4784 - val_binary_accuracy: 0.7858\n",
      "Epoch 3/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.4577 - binary_accuracy: 0.7870 - val_loss: 0.4493 - val_binary_accuracy: 0.7905\n",
      "Epoch 4/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.4197 - binary_accuracy: 0.8100 - val_loss: 0.4454 - val_binary_accuracy: 0.7882\n",
      "Epoch 5/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.3952 - binary_accuracy: 0.8194 - val_loss: 0.4510 - val_binary_accuracy: 0.7870\n",
      "Epoch 6/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.3864 - binary_accuracy: 0.8268 - val_loss: 0.4872 - val_binary_accuracy: 0.7834\n",
      "Epoch 7/100\n",
      "6530/6530 [==============================] - 1s 130us/sample - loss: 0.3541 - binary_accuracy: 0.8466 - val_loss: 0.4540 - val_binary_accuracy: 0.7893\n",
      "Epoch 8/100\n",
      "6530/6530 [==============================] - 1s 111us/sample - loss: 0.3363 - binary_accuracy: 0.8527 - val_loss: 0.4553 - val_binary_accuracy: 0.8012\n",
      "Epoch 9/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.3143 - binary_accuracy: 0.8639 - val_loss: 0.4682 - val_binary_accuracy: 0.8012\n",
      "Epoch 10/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.3038 - binary_accuracy: 0.8701 - val_loss: 0.4631 - val_binary_accuracy: 0.7941\n",
      "Epoch 11/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.2829 - binary_accuracy: 0.8816 - val_loss: 0.4597 - val_binary_accuracy: 0.7858\n",
      "Epoch 12/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.2539 - binary_accuracy: 0.8989 - val_loss: 0.4783 - val_binary_accuracy: 0.7893\n",
      "Epoch 13/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.2525 - binary_accuracy: 0.9003 - val_loss: 0.4936 - val_binary_accuracy: 0.7929\n",
      "Epoch 14/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.2306 - binary_accuracy: 0.9101 - val_loss: 0.4999 - val_binary_accuracy: 0.7811\n",
      "Epoch 15/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.2127 - binary_accuracy: 0.9187 - val_loss: 0.6058 - val_binary_accuracy: 0.7479\n",
      "Epoch 16/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.2530 - binary_accuracy: 0.8928 - val_loss: 0.5366 - val_binary_accuracy: 0.7716\n",
      "Epoch 17/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.2176 - binary_accuracy: 0.9101 - val_loss: 0.5478 - val_binary_accuracy: 0.7893\n",
      "Epoch 18/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.2052 - binary_accuracy: 0.9210 - val_loss: 0.5737 - val_binary_accuracy: 0.7799\n",
      "Epoch 19/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.2039 - binary_accuracy: 0.9194 - val_loss: 0.6547 - val_binary_accuracy: 0.7692\n",
      "Epoch 20/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.1879 - binary_accuracy: 0.9283 - val_loss: 0.6113 - val_binary_accuracy: 0.7822\n",
      "Epoch 21/100\n",
      "6530/6530 [==============================] - 1s 107us/sample - loss: 0.1751 - binary_accuracy: 0.9331 - val_loss: 0.6370 - val_binary_accuracy: 0.7775\n",
      "Epoch 22/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.1582 - binary_accuracy: 0.9452 - val_loss: 0.6186 - val_binary_accuracy: 0.7799\n",
      "Epoch 23/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.1428 - binary_accuracy: 0.9492 - val_loss: 0.6598 - val_binary_accuracy: 0.7704\n",
      "Epoch 24/100\n",
      "6530/6530 [==============================] - 1s 105us/sample - loss: 0.1427 - binary_accuracy: 0.9507 - val_loss: 0.7329 - val_binary_accuracy: 0.7775\n",
      "Epoch 25/100\n",
      "6530/6530 [==============================] - 1s 108us/sample - loss: 0.1747 - binary_accuracy: 0.9315 - val_loss: 0.7137 - val_binary_accuracy: 0.7716\n",
      "Epoch 26/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.1385 - binary_accuracy: 0.9510 - val_loss: 0.6985 - val_binary_accuracy: 0.7657\n",
      "Epoch 27/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.1164 - binary_accuracy: 0.9590 - val_loss: 0.7554 - val_binary_accuracy: 0.7669\n",
      "Epoch 28/100\n",
      "6530/6530 [==============================] - 1s 105us/sample - loss: 0.1040 - binary_accuracy: 0.9686 - val_loss: 0.7367 - val_binary_accuracy: 0.7751\n",
      "Epoch 29/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0963 - binary_accuracy: 0.9711 - val_loss: 0.7697 - val_binary_accuracy: 0.7692\n",
      "Epoch 30/100\n",
      "6530/6530 [==============================] - 1s 106us/sample - loss: 0.0869 - binary_accuracy: 0.9760 - val_loss: 0.8156 - val_binary_accuracy: 0.7704\n",
      "Epoch 31/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0842 - binary_accuracy: 0.9758 - val_loss: 0.8123 - val_binary_accuracy: 0.7751\n",
      "Epoch 32/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.0760 - binary_accuracy: 0.9783 - val_loss: 0.8448 - val_binary_accuracy: 0.7669\n",
      "Epoch 33/100\n",
      "6530/6530 [==============================] - 1s 105us/sample - loss: 0.0701 - binary_accuracy: 0.9816 - val_loss: 0.8778 - val_binary_accuracy: 0.7680\n",
      "Epoch 34/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.0643 - binary_accuracy: 0.9833 - val_loss: 0.8688 - val_binary_accuracy: 0.7680\n",
      "Epoch 35/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0613 - binary_accuracy: 0.9850 - val_loss: 0.8968 - val_binary_accuracy: 0.7598\n",
      "Epoch 36/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0614 - binary_accuracy: 0.9844 - val_loss: 0.9216 - val_binary_accuracy: 0.7680\n",
      "Epoch 37/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0654 - binary_accuracy: 0.9830 - val_loss: 0.9547 - val_binary_accuracy: 0.7527\n",
      "Epoch 38/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.0862 - binary_accuracy: 0.9709 - val_loss: 0.9299 - val_binary_accuracy: 0.7633\n",
      "Epoch 39/100\n",
      "6530/6530 [==============================] - 1s 99us/sample - loss: 0.0845 - binary_accuracy: 0.9747 - val_loss: 0.9701 - val_binary_accuracy: 0.7538\n",
      "Epoch 40/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0757 - binary_accuracy: 0.9776 - val_loss: 0.8865 - val_binary_accuracy: 0.7538\n",
      "Epoch 41/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0631 - binary_accuracy: 0.9818 - val_loss: 0.9527 - val_binary_accuracy: 0.7633\n",
      "Epoch 42/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0529 - binary_accuracy: 0.9876 - val_loss: 0.9785 - val_binary_accuracy: 0.7669\n",
      "Epoch 43/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0564 - binary_accuracy: 0.9870 - val_loss: 0.9728 - val_binary_accuracy: 0.7633\n",
      "Epoch 44/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0574 - binary_accuracy: 0.9842 - val_loss: 1.0225 - val_binary_accuracy: 0.7562\n",
      "Epoch 45/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0474 - binary_accuracy: 0.9890 - val_loss: 1.0717 - val_binary_accuracy: 0.7586\n",
      "Epoch 46/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0386 - binary_accuracy: 0.9931 - val_loss: 1.0547 - val_binary_accuracy: 0.7503\n",
      "Epoch 47/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0350 - binary_accuracy: 0.9931 - val_loss: 1.1322 - val_binary_accuracy: 0.7586\n",
      "Epoch 48/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0379 - binary_accuracy: 0.9930 - val_loss: 1.0762 - val_binary_accuracy: 0.7467\n",
      "Epoch 49/100\n",
      "6530/6530 [==============================] - 1s 106us/sample - loss: 0.0345 - binary_accuracy: 0.9917 - val_loss: 1.1339 - val_binary_accuracy: 0.7479\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0325 - binary_accuracy: 0.9942 - val_loss: 1.1193 - val_binary_accuracy: 0.7680\n",
      "Epoch 51/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0293 - binary_accuracy: 0.9949 - val_loss: 1.2222 - val_binary_accuracy: 0.7420\n",
      "Epoch 52/100\n",
      "6530/6530 [==============================] - 1s 99us/sample - loss: 0.0531 - binary_accuracy: 0.9864 - val_loss: 1.0458 - val_binary_accuracy: 0.7609\n",
      "Epoch 53/100\n",
      "6530/6530 [==============================] - 1s 99us/sample - loss: 0.0778 - binary_accuracy: 0.9753 - val_loss: 1.1720 - val_binary_accuracy: 0.7598\n",
      "Epoch 54/100\n",
      "6530/6530 [==============================] - 1s 99us/sample - loss: 0.0582 - binary_accuracy: 0.9856 - val_loss: 1.0643 - val_binary_accuracy: 0.7574\n",
      "Epoch 55/100\n",
      "6530/6530 [==============================] - 1s 98us/sample - loss: 0.0404 - binary_accuracy: 0.9908 - val_loss: 1.2079 - val_binary_accuracy: 0.7538\n",
      "Epoch 56/100\n",
      "6530/6530 [==============================] - 1s 99us/sample - loss: 0.0448 - binary_accuracy: 0.9904 - val_loss: 1.0986 - val_binary_accuracy: 0.7704\n",
      "Epoch 57/100\n",
      "6530/6530 [==============================] - 1s 98us/sample - loss: 0.0386 - binary_accuracy: 0.9907 - val_loss: 1.1219 - val_binary_accuracy: 0.7669\n",
      "Epoch 58/100\n",
      "6530/6530 [==============================] - 1s 117us/sample - loss: 0.0314 - binary_accuracy: 0.9942 - val_loss: 1.1544 - val_binary_accuracy: 0.7538\n",
      "Epoch 59/100\n",
      "6530/6530 [==============================] - 1s 122us/sample - loss: 0.0256 - binary_accuracy: 0.9969 - val_loss: 1.1800 - val_binary_accuracy: 0.7586\n",
      "Epoch 60/100\n",
      "6530/6530 [==============================] - 1s 117us/sample - loss: 0.0225 - binary_accuracy: 0.9969 - val_loss: 1.1957 - val_binary_accuracy: 0.7657\n",
      "Epoch 61/100\n",
      "6530/6530 [==============================] - 1s 116us/sample - loss: 0.0186 - binary_accuracy: 0.9980 - val_loss: 1.2400 - val_binary_accuracy: 0.7609\n",
      "Epoch 62/100\n",
      "6530/6530 [==============================] - 1s 107us/sample - loss: 0.0161 - binary_accuracy: 0.9986 - val_loss: 1.2519 - val_binary_accuracy: 0.7633\n",
      "Epoch 63/100\n",
      "6530/6530 [==============================] - 1s 98us/sample - loss: 0.0143 - binary_accuracy: 0.9986 - val_loss: 1.2852 - val_binary_accuracy: 0.7609\n",
      "Epoch 64/100\n",
      "6530/6530 [==============================] - 1s 98us/sample - loss: 0.0131 - binary_accuracy: 0.9991 - val_loss: 1.2678 - val_binary_accuracy: 0.7645\n",
      "Epoch 65/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0122 - binary_accuracy: 0.9991 - val_loss: 1.2855 - val_binary_accuracy: 0.7621\n",
      "Epoch 66/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0113 - binary_accuracy: 0.9992 - val_loss: 1.2904 - val_binary_accuracy: 0.7645\n",
      "Epoch 67/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0126 - binary_accuracy: 0.9989 - val_loss: 1.2461 - val_binary_accuracy: 0.7598\n",
      "Epoch 68/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.0264 - binary_accuracy: 0.9942 - val_loss: 1.2820 - val_binary_accuracy: 0.7491\n",
      "Epoch 69/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0263 - binary_accuracy: 0.9949 - val_loss: 1.2826 - val_binary_accuracy: 0.7527\n",
      "Epoch 70/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.0182 - binary_accuracy: 0.9979 - val_loss: 1.3399 - val_binary_accuracy: 0.7598\n",
      "Epoch 71/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.0142 - binary_accuracy: 0.9988 - val_loss: 1.3924 - val_binary_accuracy: 0.7633\n",
      "Epoch 72/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0130 - binary_accuracy: 0.9991 - val_loss: 1.4318 - val_binary_accuracy: 0.7621\n",
      "Epoch 73/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.0138 - binary_accuracy: 0.9983 - val_loss: 1.3543 - val_binary_accuracy: 0.7645\n",
      "Epoch 74/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.0119 - binary_accuracy: 0.9991 - val_loss: 1.3676 - val_binary_accuracy: 0.7645\n",
      "Epoch 75/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0141 - binary_accuracy: 0.9985 - val_loss: 1.3263 - val_binary_accuracy: 0.7562\n",
      "Epoch 76/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.0200 - binary_accuracy: 0.9972 - val_loss: 1.2910 - val_binary_accuracy: 0.7704\n",
      "Epoch 77/100\n",
      "6530/6530 [==============================] - 1s 99us/sample - loss: 0.0297 - binary_accuracy: 0.9939 - val_loss: 1.3097 - val_binary_accuracy: 0.7562\n",
      "Epoch 78/100\n",
      "6530/6530 [==============================] - 1s 98us/sample - loss: 0.0310 - binary_accuracy: 0.9931 - val_loss: 1.3501 - val_binary_accuracy: 0.7586\n",
      "Epoch 79/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0399 - binary_accuracy: 0.9885 - val_loss: 1.3612 - val_binary_accuracy: 0.7657\n",
      "Epoch 80/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.0325 - binary_accuracy: 0.9914 - val_loss: 1.2645 - val_binary_accuracy: 0.7645\n",
      "Epoch 81/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.0297 - binary_accuracy: 0.9948 - val_loss: 1.2848 - val_binary_accuracy: 0.7645\n",
      "Epoch 82/100\n",
      "6530/6530 [==============================] - 1s 99us/sample - loss: 0.0531 - binary_accuracy: 0.9855 - val_loss: 1.2881 - val_binary_accuracy: 0.7657\n",
      "Epoch 83/100\n",
      "6530/6530 [==============================] - 1s 99us/sample - loss: 0.0334 - binary_accuracy: 0.9900 - val_loss: 1.3814 - val_binary_accuracy: 0.7657\n",
      "Epoch 84/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0198 - binary_accuracy: 0.9969 - val_loss: 1.3153 - val_binary_accuracy: 0.7538\n",
      "Epoch 85/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0176 - binary_accuracy: 0.9971 - val_loss: 1.4050 - val_binary_accuracy: 0.7621\n",
      "Epoch 86/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.0161 - binary_accuracy: 0.9979 - val_loss: 1.4065 - val_binary_accuracy: 0.7609\n",
      "Epoch 87/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.0162 - binary_accuracy: 0.9974 - val_loss: 1.4259 - val_binary_accuracy: 0.7657\n",
      "Epoch 88/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0147 - binary_accuracy: 0.9985 - val_loss: 1.3893 - val_binary_accuracy: 0.7598\n",
      "Epoch 89/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0136 - binary_accuracy: 0.9989 - val_loss: 1.4301 - val_binary_accuracy: 0.7680\n",
      "Epoch 90/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0114 - binary_accuracy: 0.9989 - val_loss: 1.3951 - val_binary_accuracy: 0.7645\n",
      "Epoch 91/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0464 - binary_accuracy: 0.9859 - val_loss: 1.4784 - val_binary_accuracy: 0.7538\n",
      "Epoch 92/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0604 - binary_accuracy: 0.9832 - val_loss: 1.3230 - val_binary_accuracy: 0.7396\n",
      "Epoch 93/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0548 - binary_accuracy: 0.9855 - val_loss: 1.2973 - val_binary_accuracy: 0.7621\n",
      "Epoch 94/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.0355 - binary_accuracy: 0.9911 - val_loss: 1.3681 - val_binary_accuracy: 0.7609\n",
      "Epoch 95/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0364 - binary_accuracy: 0.9902 - val_loss: 1.3755 - val_binary_accuracy: 0.7574\n",
      "Epoch 96/100\n",
      "6530/6530 [==============================] - 1s 105us/sample - loss: 0.0273 - binary_accuracy: 0.9940 - val_loss: 1.3610 - val_binary_accuracy: 0.7586\n",
      "Epoch 97/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.0219 - binary_accuracy: 0.9960 - val_loss: 1.4724 - val_binary_accuracy: 0.7562\n",
      "Epoch 98/100\n",
      "6530/6530 [==============================] - 1s 98us/sample - loss: 0.0134 - binary_accuracy: 0.9991 - val_loss: 1.3816 - val_binary_accuracy: 0.7562\n",
      "Epoch 99/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.0107 - binary_accuracy: 0.9995 - val_loss: 1.4480 - val_binary_accuracy: 0.7515\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.0085 - binary_accuracy: 0.9998 - val_loss: 1.4365 - val_binary_accuracy: 0.7621\n"
     ]
    }
   ],
   "source": [
    "vanilla_lstm_hist = run_model(model_args = {'layer_type': tf.keras.layers.LSTM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398  words from dataset not in glove\n",
      "Train on 6530 samples, validate on 845 samples\n",
      "Epoch 1/100\n",
      "6530/6530 [==============================] - 2s 277us/sample - loss: 0.6417 - binary_accuracy: 0.6250 - val_loss: 0.5556 - val_binary_accuracy: 0.7266\n",
      "Epoch 2/100\n",
      "6530/6530 [==============================] - 1s 93us/sample - loss: 0.5248 - binary_accuracy: 0.7380 - val_loss: 0.4822 - val_binary_accuracy: 0.7728\n",
      "Epoch 3/100\n",
      "6530/6530 [==============================] - 1s 93us/sample - loss: 0.4636 - binary_accuracy: 0.7838 - val_loss: 0.4630 - val_binary_accuracy: 0.7882\n",
      "Epoch 4/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.4305 - binary_accuracy: 0.8034 - val_loss: 0.4639 - val_binary_accuracy: 0.7905\n",
      "Epoch 5/100\n",
      "6530/6530 [==============================] - 1s 96us/sample - loss: 0.3971 - binary_accuracy: 0.8179 - val_loss: 0.4660 - val_binary_accuracy: 0.7834\n",
      "Epoch 6/100\n",
      "6530/6530 [==============================] - 1s 97us/sample - loss: 0.4008 - binary_accuracy: 0.8196 - val_loss: 0.4650 - val_binary_accuracy: 0.7893\n",
      "Epoch 7/100\n",
      "6530/6530 [==============================] - 1s 96us/sample - loss: 0.3592 - binary_accuracy: 0.8432 - val_loss: 0.5027 - val_binary_accuracy: 0.7799\n",
      "Epoch 8/100\n",
      "6530/6530 [==============================] - 1s 97us/sample - loss: 0.3326 - binary_accuracy: 0.8594 - val_loss: 0.4910 - val_binary_accuracy: 0.7775\n",
      "Epoch 9/100\n",
      "6530/6530 [==============================] - 1s 96us/sample - loss: 0.3156 - binary_accuracy: 0.8692 - val_loss: 0.5155 - val_binary_accuracy: 0.7751\n",
      "Epoch 10/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.2963 - binary_accuracy: 0.8815 - val_loss: 0.5341 - val_binary_accuracy: 0.7787\n",
      "Epoch 11/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.2777 - binary_accuracy: 0.8914 - val_loss: 0.5294 - val_binary_accuracy: 0.7858\n",
      "Epoch 12/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.2605 - binary_accuracy: 0.8968 - val_loss: 0.5305 - val_binary_accuracy: 0.7775\n",
      "Epoch 13/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.2447 - binary_accuracy: 0.9038 - val_loss: 0.5390 - val_binary_accuracy: 0.7893\n",
      "Epoch 14/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.2217 - binary_accuracy: 0.9178 - val_loss: 0.5925 - val_binary_accuracy: 0.7834\n",
      "Epoch 15/100\n",
      "6530/6530 [==============================] - 1s 97us/sample - loss: 0.2023 - binary_accuracy: 0.9271 - val_loss: 0.5938 - val_binary_accuracy: 0.7870\n",
      "Epoch 16/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.1915 - binary_accuracy: 0.9276 - val_loss: 0.6120 - val_binary_accuracy: 0.7822\n",
      "Epoch 17/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.1857 - binary_accuracy: 0.9338 - val_loss: 0.6438 - val_binary_accuracy: 0.7775\n",
      "Epoch 18/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.1648 - binary_accuracy: 0.9417 - val_loss: 0.6745 - val_binary_accuracy: 0.7775\n",
      "Epoch 19/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.1513 - binary_accuracy: 0.9495 - val_loss: 0.6969 - val_binary_accuracy: 0.7858\n",
      "Epoch 20/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.1464 - binary_accuracy: 0.9495 - val_loss: 0.7083 - val_binary_accuracy: 0.7822\n",
      "Epoch 21/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.1299 - binary_accuracy: 0.9557 - val_loss: 0.7470 - val_binary_accuracy: 0.7657\n",
      "Epoch 22/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.1238 - binary_accuracy: 0.9573 - val_loss: 0.7424 - val_binary_accuracy: 0.7740\n",
      "Epoch 23/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.1170 - binary_accuracy: 0.9637 - val_loss: 0.8258 - val_binary_accuracy: 0.7609\n",
      "Epoch 24/100\n",
      "6530/6530 [==============================] - 1s 96us/sample - loss: 0.1225 - binary_accuracy: 0.9556 - val_loss: 0.7689 - val_binary_accuracy: 0.7669\n",
      "Epoch 25/100\n",
      "6530/6530 [==============================] - 1s 97us/sample - loss: 0.1251 - binary_accuracy: 0.9530 - val_loss: 0.8482 - val_binary_accuracy: 0.7751\n",
      "Epoch 26/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.1058 - binary_accuracy: 0.9608 - val_loss: 0.8408 - val_binary_accuracy: 0.7562\n",
      "Epoch 27/100\n",
      "6530/6530 [==============================] - 1s 96us/sample - loss: 0.0935 - binary_accuracy: 0.9680 - val_loss: 0.8900 - val_binary_accuracy: 0.7669\n",
      "Epoch 28/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.0770 - binary_accuracy: 0.9763 - val_loss: 0.9108 - val_binary_accuracy: 0.7621\n",
      "Epoch 29/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.0810 - binary_accuracy: 0.9744 - val_loss: 0.9474 - val_binary_accuracy: 0.7692\n",
      "Epoch 30/100\n",
      "6530/6530 [==============================] - 1s 97us/sample - loss: 0.1019 - binary_accuracy: 0.9643 - val_loss: 1.0139 - val_binary_accuracy: 0.7503\n",
      "Epoch 31/100\n",
      "6530/6530 [==============================] - 1s 100us/sample - loss: 0.1003 - binary_accuracy: 0.9614 - val_loss: 0.9761 - val_binary_accuracy: 0.7657\n",
      "Epoch 32/100\n",
      "6530/6530 [==============================] - 1s 98us/sample - loss: 0.0979 - binary_accuracy: 0.9680 - val_loss: 0.9884 - val_binary_accuracy: 0.7574\n",
      "Epoch 33/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.0802 - binary_accuracy: 0.9730 - val_loss: 1.0345 - val_binary_accuracy: 0.7574\n",
      "Epoch 34/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.0605 - binary_accuracy: 0.9822 - val_loss: 1.0609 - val_binary_accuracy: 0.7621\n",
      "Epoch 35/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.0467 - binary_accuracy: 0.9882 - val_loss: 1.0894 - val_binary_accuracy: 0.7657\n",
      "Epoch 36/100\n",
      "6530/6530 [==============================] - 1s 96us/sample - loss: 0.0383 - binary_accuracy: 0.9925 - val_loss: 1.1231 - val_binary_accuracy: 0.7586\n",
      "Epoch 37/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.0327 - binary_accuracy: 0.9936 - val_loss: 1.1740 - val_binary_accuracy: 0.7562\n",
      "Epoch 38/100\n",
      "6530/6530 [==============================] - 1s 96us/sample - loss: 0.0374 - binary_accuracy: 0.9919 - val_loss: 1.1713 - val_binary_accuracy: 0.7645\n",
      "Epoch 39/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.0460 - binary_accuracy: 0.9882 - val_loss: 1.1752 - val_binary_accuracy: 0.7609\n",
      "Epoch 40/100\n",
      "6530/6530 [==============================] - 1s 93us/sample - loss: 0.0913 - binary_accuracy: 0.9681 - val_loss: 1.0666 - val_binary_accuracy: 0.7657\n",
      "Epoch 41/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.0801 - binary_accuracy: 0.9724 - val_loss: 1.1432 - val_binary_accuracy: 0.7550\n",
      "Epoch 42/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.0524 - binary_accuracy: 0.9841 - val_loss: 1.1683 - val_binary_accuracy: 0.7669\n",
      "Epoch 43/100\n",
      "6530/6530 [==============================] - 1s 93us/sample - loss: 0.0362 - binary_accuracy: 0.9914 - val_loss: 1.2300 - val_binary_accuracy: 0.7598\n",
      "Epoch 44/100\n",
      "6530/6530 [==============================] - 1s 93us/sample - loss: 0.0380 - binary_accuracy: 0.9910 - val_loss: 1.2023 - val_binary_accuracy: 0.7621\n",
      "Epoch 45/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.0354 - binary_accuracy: 0.9928 - val_loss: 1.2114 - val_binary_accuracy: 0.7621\n",
      "Epoch 46/100\n",
      "6530/6530 [==============================] - 1s 96us/sample - loss: 0.1054 - binary_accuracy: 0.9657 - val_loss: 1.1454 - val_binary_accuracy: 0.7550\n",
      "Epoch 47/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.0943 - binary_accuracy: 0.9677 - val_loss: 1.1404 - val_binary_accuracy: 0.7538\n",
      "Epoch 48/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0781 - binary_accuracy: 0.9727 - val_loss: 1.1893 - val_binary_accuracy: 0.7550\n",
      "Epoch 49/100\n",
      "6530/6530 [==============================] - 1s 113us/sample - loss: 0.0561 - binary_accuracy: 0.9827 - val_loss: 1.2497 - val_binary_accuracy: 0.7479\n",
      "Epoch 50/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0430 - binary_accuracy: 0.9870 - val_loss: 1.2495 - val_binary_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0407 - binary_accuracy: 0.9882 - val_loss: 1.2747 - val_binary_accuracy: 0.7562\n",
      "Epoch 52/100\n",
      "6530/6530 [==============================] - 1s 93us/sample - loss: 0.0340 - binary_accuracy: 0.9916 - val_loss: 1.2780 - val_binary_accuracy: 0.7527\n",
      "Epoch 53/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.0421 - binary_accuracy: 0.9885 - val_loss: 1.2560 - val_binary_accuracy: 0.7621\n",
      "Epoch 54/100\n",
      "6530/6530 [==============================] - 1s 124us/sample - loss: 0.0487 - binary_accuracy: 0.9827 - val_loss: 1.3415 - val_binary_accuracy: 0.7479\n",
      "Epoch 55/100\n",
      "6530/6530 [==============================] - 1s 146us/sample - loss: 0.0415 - binary_accuracy: 0.9881 - val_loss: 1.4530 - val_binary_accuracy: 0.7503\n",
      "Epoch 56/100\n",
      "6530/6530 [==============================] - 1s 108us/sample - loss: 0.0372 - binary_accuracy: 0.9907 - val_loss: 1.3891 - val_binary_accuracy: 0.7550\n",
      "Epoch 57/100\n",
      "6530/6530 [==============================] - 1s 110us/sample - loss: 0.0349 - binary_accuracy: 0.9893 - val_loss: 1.3717 - val_binary_accuracy: 0.7538\n",
      "Epoch 58/100\n",
      "6530/6530 [==============================] - 1s 111us/sample - loss: 0.0261 - binary_accuracy: 0.9945 - val_loss: 1.3710 - val_binary_accuracy: 0.7574\n",
      "Epoch 59/100\n",
      "6530/6530 [==============================] - 1s 113us/sample - loss: 0.0197 - binary_accuracy: 0.9969 - val_loss: 1.4580 - val_binary_accuracy: 0.7574\n",
      "Epoch 60/100\n",
      "6530/6530 [==============================] - 1s 110us/sample - loss: 0.0146 - binary_accuracy: 0.9980 - val_loss: 1.4967 - val_binary_accuracy: 0.7538\n",
      "Epoch 61/100\n",
      "6530/6530 [==============================] - 1s 107us/sample - loss: 0.0109 - binary_accuracy: 0.9992 - val_loss: 1.5192 - val_binary_accuracy: 0.7550\n",
      "Epoch 62/100\n",
      "6530/6530 [==============================] - 1s 111us/sample - loss: 0.0093 - binary_accuracy: 0.9995 - val_loss: 1.5287 - val_binary_accuracy: 0.7574\n",
      "Epoch 63/100\n",
      "6530/6530 [==============================] - 1s 111us/sample - loss: 0.0082 - binary_accuracy: 0.9995 - val_loss: 1.5808 - val_binary_accuracy: 0.7574\n",
      "Epoch 64/100\n",
      "6530/6530 [==============================] - 1s 95us/sample - loss: 0.0071 - binary_accuracy: 0.9998 - val_loss: 1.5859 - val_binary_accuracy: 0.7586\n",
      "Epoch 65/100\n",
      "6530/6530 [==============================] - 1s 109us/sample - loss: 0.0066 - binary_accuracy: 0.9998 - val_loss: 1.6230 - val_binary_accuracy: 0.7538\n",
      "Epoch 66/100\n",
      "6530/6530 [==============================] - 1s 106us/sample - loss: 0.0059 - binary_accuracy: 0.9998 - val_loss: 1.6043 - val_binary_accuracy: 0.7586\n",
      "Epoch 67/100\n",
      "6530/6530 [==============================] - 1s 112us/sample - loss: 0.0053 - binary_accuracy: 1.0000 - val_loss: 1.6455 - val_binary_accuracy: 0.7550\n",
      "Epoch 68/100\n",
      "6530/6530 [==============================] - 1s 110us/sample - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 1.6673 - val_binary_accuracy: 0.7527\n",
      "Epoch 69/100\n",
      "6530/6530 [==============================] - 1s 110us/sample - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 1.6544 - val_binary_accuracy: 0.7621\n",
      "Epoch 70/100\n",
      "6530/6530 [==============================] - 1s 108us/sample - loss: 0.0043 - binary_accuracy: 1.0000 - val_loss: 1.6955 - val_binary_accuracy: 0.7550\n",
      "Epoch 71/100\n",
      "6530/6530 [==============================] - 1s 112us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 1.6845 - val_binary_accuracy: 0.7609\n",
      "Epoch 72/100\n",
      "6530/6530 [==============================] - 1s 103us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - val_loss: 1.7153 - val_binary_accuracy: 0.7538\n",
      "Epoch 73/100\n",
      "6530/6530 [==============================] - 1s 98us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 1.6967 - val_binary_accuracy: 0.7609\n",
      "Epoch 74/100\n",
      "6530/6530 [==============================] - 1s 110us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - val_loss: 1.7360 - val_binary_accuracy: 0.7550\n",
      "Epoch 75/100\n",
      "6530/6530 [==============================] - 1s 110us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 1.7379 - val_binary_accuracy: 0.7598\n",
      "Epoch 76/100\n",
      "6530/6530 [==============================] - 1s 107us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 1.7554 - val_binary_accuracy: 0.7586\n",
      "Epoch 77/100\n",
      "6530/6530 [==============================] - 1s 116us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 1.7687 - val_binary_accuracy: 0.7598\n",
      "Epoch 78/100\n",
      "6530/6530 [==============================] - 1s 114us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 1.7900 - val_binary_accuracy: 0.7586\n",
      "Epoch 79/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 1.7945 - val_binary_accuracy: 0.7586\n",
      "Epoch 80/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 1.8086 - val_binary_accuracy: 0.7621\n",
      "Epoch 81/100\n",
      "6530/6530 [==============================] - 1s 107us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - val_loss: 1.8212 - val_binary_accuracy: 0.7586\n",
      "Epoch 82/100\n",
      "6530/6530 [==============================] - 1s 105us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 1.8235 - val_binary_accuracy: 0.7645\n",
      "Epoch 83/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 1.8393 - val_binary_accuracy: 0.7598\n",
      "Epoch 84/100\n",
      "6530/6530 [==============================] - 1s 105us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 1.8476 - val_binary_accuracy: 0.7609\n",
      "Epoch 85/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 1.8586 - val_binary_accuracy: 0.7609\n",
      "Epoch 86/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 1.8689 - val_binary_accuracy: 0.7586\n",
      "Epoch 87/100\n",
      "6530/6530 [==============================] - 1s 116us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 1.8781 - val_binary_accuracy: 0.7598\n",
      "Epoch 88/100\n",
      "6530/6530 [==============================] - 1s 115us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 1.8855 - val_binary_accuracy: 0.7598\n",
      "Epoch 89/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 1.8867 - val_binary_accuracy: 0.7609\n",
      "Epoch 90/100\n",
      "6530/6530 [==============================] - 1s 115us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 1.9030 - val_binary_accuracy: 0.7598\n",
      "Epoch 91/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 1.9100 - val_binary_accuracy: 0.7598\n",
      "Epoch 92/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 1.9201 - val_binary_accuracy: 0.7598\n",
      "Epoch 93/100\n",
      "6530/6530 [==============================] - 1s 106us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 1.9247 - val_binary_accuracy: 0.7609\n",
      "Epoch 94/100\n",
      "6530/6530 [==============================] - 1s 101us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 1.9361 - val_binary_accuracy: 0.7574\n",
      "Epoch 95/100\n",
      "6530/6530 [==============================] - 1s 102us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 1.9420 - val_binary_accuracy: 0.7586\n",
      "Epoch 96/100\n",
      "6530/6530 [==============================] - 1s 98us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 1.9536 - val_binary_accuracy: 0.7598\n",
      "Epoch 97/100\n",
      "6530/6530 [==============================] - 1s 105us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 1.9599 - val_binary_accuracy: 0.7586\n",
      "Epoch 98/100\n",
      "6530/6530 [==============================] - 1s 104us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 1.9670 - val_binary_accuracy: 0.7598\n",
      "Epoch 99/100\n",
      "6530/6530 [==============================] - 1s 94us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 1.9638 - val_binary_accuracy: 0.7609\n",
      "Epoch 100/100\n",
      "6530/6530 [==============================] - 1s 106us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 1.9735 - val_binary_accuracy: 0.7586\n"
     ]
    }
   ],
   "source": [
    "vanilla_gru_hist = run_model(model_args = {'layer_type': tf.keras.layers.GRU})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
